{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxa2g4UDgW9y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('hdddata.csv')\n",
        "\n",
        "# Select two classes for binary classification\n",
        "class_1 = 0  # Replace with the desired class\n",
        "class_2 = 1  # Replace with the desired class\n",
        "\n",
        "# Filter the dataset for the selected classes\n",
        "binary_data = data[(data['failure'] == class_1) | (data['failure'] == class_2)]\n",
        "\n",
        "# Separate features and target variable\n",
        "X = binary_data.drop('failure', axis=1)  # Features\n",
        "y = binary_data['failure']  # Target variable\n",
        "\n",
        "# Impute missing values (NaN) with the mean of the column\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Splitting the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initializing SVM classifier\n",
        "clf = svm.SVC()\n",
        "\n",
        "# Training the SVM classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# A1. Get the support vectors and study them\n",
        "support_vectors = clf.support_vectors_\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A2. Test the accuracy of the SVM\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "aKekynFFlgpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A3. Using the predict function to study output values\n",
        "predicted_classes = clf.predict(X_test)\n",
        "print(\"Predicted classes:\", predicted_classes)"
      ],
      "metadata": {
        "id": "vKtBnbjPloCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing accuracy using own logic of class determination and comparing against class labels\n",
        "own_accuracy = accuracy_score(y_test, predicted_classes)\n",
        "print(\"Accuracy using own logic:\", own_accuracy)\n"
      ],
      "metadata": {
        "id": "cg8UydjjltuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A4. Experimenting with various kernel functions\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "for kernel in kernels:\n",
        "    clf = svm.SVC(kernel=kernel)\n",
        "    clf.fit(X_train, y_train)\n",
        "    accuracy = clf.score(X_test, y_test)\n",
        "    print(f\"Accuracy with {kernel} kernel:\", accuracy)\n"
      ],
      "metadata": {
        "id": "9zaJGaFGlwst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}